10/2022,ğŸ“„ğŸ§ ,Super excited to have my first PNAS paper accepted: "<em><a href="websiteRoot/publications.html#sap2022quantifying">Quantifying the narrative flow of imagined versus autobiographical stories</a></em>" out soon!
09/2022,ğŸ“„âš–,Excited to have my first NeurIPS paper accepted, called "<em>Rule-Based but Flexible? Evaluating and Improving Language Models as Accounts of Human Moral Judgment</em>." Stay tuned for the camera ready version.
08/2022,âœˆğŸ™,I moved to Pittsburgh to officially start at <a href="https://www.lti.cs.cmu.edu/" target="_blank">CMU's LTI</a> department as an assistant professorğŸ‘¨ğŸ¼â€ğŸ«. â€
07/2022,ğŸ‘¨ğŸ¼â€ğŸ«,I'll be attending NAACL and giving a talk about <em><a href="websiteRoot/publications.html#sap2022annotatorsWithAttitudes">Annotators with Attitudes</a></em> during session 5A: "<em>Ethics, Bias, Fairness 1</em>" between 14:15 â€“ 15:45 PST Tuesday July 12.
04/2022,,Giving a keynote talk at the <a href="https://caisa.informatik.uni-marburg.de/user_nlp.html">UserNLP: User-centered Natural Language Processing Workshop</a> collocated with <a href="https://www2022.thewebconf.org/">the WebConf 2022</a> on my research! Video coming soon.
04/2022,ğŸ‘¨ğŸ¼â€ğŸ«,I gave a talk at UPenn's Computational Linguistics Lunch (CLunch) on <em>Detecting and Rewriting Social Biases in Language</em>.
04/2022,ğŸ“„,Excited that we have two papers accepted to NAACL 2022 in â˜” Seattle ğŸ”: our preprint on annotator variation in toxicity labelling: <em><a href="websiteRoot/publications.html#sap2022annotatorsWithAttitudes">Annotators with Attitudes: How Annotator Beliefs And Identities Bias Toxic Language Detection</a></em>, and our new work on steering agents to do the "right thing" in text games with reinforcement learning: <em><a href="websiteRoot/publications.html#ammanabrolu2022galad">Aligning to Social Norms and Values in Interactive Narratives</a></em>
02/2022,ğŸ“„,Got two papers accepted to ACL 2022 in ğŸ€ Dublin ğŸ€: our paper on generating hate speech datasets with GPT-3: <em><a href="websiteRoot/publications.html#hartvigsen2022toxigen">TOXIGEN: Controlling Language Models to Generate Implied and Adversarial Toxicity</a></em>, and our paper on distilling reactions to headlines to combat misinformation: <em><a href="websiteRoot/publications.html#gabriel2022misinfoReactionFrames">Misinfo Reaction Frames: Reasoning about Readers' Reactions to News Headlines</a></em>
02/2022,ğŸ‘¨ğŸ¼â€ğŸ«,I gave an invited talk at UIUC's Responsible Data Science seminar on my research.
02/2022,ğŸ‘¨ğŸ¼â€ğŸ«,I gave guest lectures on <em>Detecting and Rewriting Social Biases in Language</em> at <a href="https://web.stanford.edu/class/cs224n/">Stanford's Deep Learning for NLP course (CS224N)</a> and at LTI's Computational Ethics course (CS 11-830), and a guest lecture on <em>Positive AI with Social Commonsense Models</em> in UBC's commonsense reasoning course.
12/2021,ğŸ§‘â€ğŸ“,I will likely be taking students this coming PhD application cycle. If you're interested in working with me on <em>social commonsense, social biases in language, or ethics in AI</em>, please apply to <a href="https://www.lti.cs.cmu.edu/apply-lti" target="_blank">CMU's LTI</a>.
07/2021,ğŸ‘¨ğŸ¼â€ğŸ“,I successfully defended my PhD thesis titled <em>Positive AI with Social Commonsense Models</em> (<a target="_blank" href="pdfs/sap2021positiveAIwithSocialCommonsenseModels.pdf">read the thesis here</a>, or <a href="https://www.youtube.com/watch?v=VKd4Y7Ykh6o" target="_blank">watch the recording here<a/>). Thanks to my advisors, committee, and everyone who attended!
05/2021,ğŸ¥³,I will be joining <a href="https://www.lti.cs.cmu.edu/" target="_blank">CMU's LTI</a> department as an assistant professorğŸ‘¨ğŸ¼â€ğŸ«in Fall 2022. If you wish to work with me, <a href="contact.html">see the "contact" page</a>. Before starting there, I will be a postdoc at <a href="https://allenai.org" target="_blank">AI2</a> on project <a target="_blank" href="https://allenai.org/commonsense/">Mosaic</a> ğŸ‘¨ğŸ¼â€ğŸ”¬ starting Fall 2021.
01/2021,ğŸ“°,...started this list ğŸ˜ which I probably should have done sooner ğŸ˜…