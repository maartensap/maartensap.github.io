10/2022,📄🧠,Super excited to have my first PNAS paper accepted: "<em><a href="websiteRoot/publications.html#sap2022quantifying">Quantifying the narrative flow of imagined versus autobiographical stories</a></em>" out soon!
09/2022,📄⚖,Excited to have my first NeurIPS paper accepted, called "<em>Rule-Based but Flexible? Evaluating and Improving Language Models as Accounts of Human Moral Judgment</em>." Stay tuned for the camera ready version.
08/2022,✈🏙,I moved to Pittsburgh to officially start at <a href="https://www.lti.cs.cmu.edu/" target="_blank">CMU's LTI</a> department as an assistant professor👨🏼‍🏫. ‍
07/2022,👨🏼‍🏫,I'll be attending NAACL and giving a talk about <em><a href="websiteRoot/publications.html#sap2022annotatorsWithAttitudes">Annotators with Attitudes</a></em> during session 5A: "<em>Ethics, Bias, Fairness 1</em>" between 14:15 – 15:45 PST Tuesday July 12.
04/2022,,Giving a keynote talk at the <a href="https://caisa.informatik.uni-marburg.de/user_nlp.html">UserNLP: User-centered Natural Language Processing Workshop</a> collocated with <a href="https://www2022.thewebconf.org/">the WebConf 2022</a> on my research! Video coming soon.
04/2022,👨🏼‍🏫,I gave a talk at UPenn's Computational Linguistics Lunch (CLunch) on <em>Detecting and Rewriting Social Biases in Language</em>.
04/2022,📄,Excited that we have two papers accepted to NAACL 2022 in ☔ Seattle 🏔: our preprint on annotator variation in toxicity labelling: <em><a href="websiteRoot/publications.html#sap2022annotatorsWithAttitudes">Annotators with Attitudes: How Annotator Beliefs And Identities Bias Toxic Language Detection</a></em>, and our new work on steering agents to do the "right thing" in text games with reinforcement learning: <em><a href="websiteRoot/publications.html#ammanabrolu2022galad">Aligning to Social Norms and Values in Interactive Narratives</a></em>
02/2022,📄,Got two papers accepted to ACL 2022 in 🍀 Dublin 🍀: our paper on generating hate speech datasets with GPT-3: <em><a href="websiteRoot/publications.html#hartvigsen2022toxigen">TOXIGEN: Controlling Language Models to Generate Implied and Adversarial Toxicity</a></em>, and our paper on distilling reactions to headlines to combat misinformation: <em><a href="websiteRoot/publications.html#gabriel2022misinfoReactionFrames">Misinfo Reaction Frames: Reasoning about Readers' Reactions to News Headlines</a></em>
02/2022,👨🏼‍🏫,I gave an invited talk at UIUC's Responsible Data Science seminar on my research.
02/2022,👨🏼‍🏫,I gave guest lectures on <em>Detecting and Rewriting Social Biases in Language</em> at <a href="https://web.stanford.edu/class/cs224n/">Stanford's Deep Learning for NLP course (CS224N)</a> and at LTI's Computational Ethics course (CS 11-830), and a guest lecture on <em>Positive AI with Social Commonsense Models</em> in UBC's commonsense reasoning course.
12/2021,🧑‍🎓,I will likely be taking students this coming PhD application cycle. If you're interested in working with me on <em>social commonsense, social biases in language, or ethics in AI</em>, please apply to <a href="https://www.lti.cs.cmu.edu/apply-lti" target="_blank">CMU's LTI</a>.
07/2021,👨🏼‍🎓,I successfully defended my PhD thesis titled <em>Positive AI with Social Commonsense Models</em> (<a target="_blank" href="pdfs/sap2021positiveAIwithSocialCommonsenseModels.pdf">read the thesis here</a>, or <a href="https://www.youtube.com/watch?v=VKd4Y7Ykh6o" target="_blank">watch the recording here<a/>). Thanks to my advisors, committee, and everyone who attended!
05/2021,🥳,I will be joining <a href="https://www.lti.cs.cmu.edu/" target="_blank">CMU's LTI</a> department as an assistant professor👨🏼‍🏫in Fall 2022. If you wish to work with me, <a href="contact.html">see the "contact" page</a>. Before starting there, I will be a postdoc at <a href="https://allenai.org" target="_blank">AI2</a> on project <a target="_blank" href="https://allenai.org/commonsense/">Mosaic</a> 👨🏼‍🔬 starting Fall 2021.
01/2021,📰,...started this list 😁 which I probably should have done sooner 😅