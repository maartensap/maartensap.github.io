11/2023,ğŸ“°ğŸ¦,Excited to unveil the camera-ready versions of our EMNLP papers! 
*["Don't Take This Out of Context!" On the Need for Contextual Models and Evaluations for Stylistic Rewriting](https://arxiv.org/abs/2305.14755)*, *[SODA: Million-scale Dialogue Distillation with Social Commonsense Contextualization](https://arxiv.org/abs/2212.10465)*, *[FANToM: A Benchmark for Stress-testing Machine Theory of Mind in Interactions](https://arxiv.org/abs/2310.15421)*, *[Modeling Empathic Similarity in Personal Narratives](https://arxiv.org/abs/2305.14246)*, *[BiasX: "Thinking Slow" in Toxic Language Annotation with Explanations of Implied Social Biases](https://arxiv.org/abs/2305.13589)*, and *[Beyond Denouncing Hate: Strategies for Countering Implied Biases and Stereotypes in Language](https://arxiv.org/abs/2311.00161)*.
08/2023,ğŸ‘¨ğŸ¼â€ğŸ«,Year two of being a professor has started! I'm excited about this coming year, and teaching the [Data Science Seminar](https://mcds-cmu.github.io/11631/f23/)!
08/2023,ğŸ¶ğŸ—½,I was invited to give a remote talk about *The Pivotal Role of Social Context in Toxic Language Detection* to Spotify's Ethical AI team!
07/2023,ğŸ’»ğŸŒº,Excited to give a (virtual) keynote talk at the first [Workshop on Theory of Mind at ICML 2023](https://tomworkshop.github.io/): *Towards Socially Aware AI with Pragmatic Competence*
07/2023,ğŸ³ï¸â€ğŸŒˆğŸ†,Extremely excited to share that we won an ***Outstanding Paper award*** for our ACL 2023 paper *[NLPositionality: Characterizing Design Biases of Datasets and Models](./pdfs/santy2023nlpositionality.pdf)* with [Sebastin](http://sebastinsanty.com/), [Jenny](https://jennyliang.me/), [Ronan](https://rlebras.github.io/), and [Katharina](https://homes.cs.washington.edu/~reinecke/)!
07/2023,âœˆğŸ‡¨ğŸ‡¦,Excited to travel to ACL 2023 in Toronto along with my mentees and PhD students! I'll be giving a keynote at the [Workshop on Online Abuse and Harms](https://www.workshopononlineabuse.com/) on *The Pivotal Role of Social Context in Toxic Language Detection* on Thursday at 11:45am (Pier 7 & 8)
06/2023,ğŸ³ï¸â€ğŸŒˆğŸ†,Super excited that our paper *[Queer In AI: A Case Study in Community-Led Participatory AI](websiteRoot/publications.html#OrganizersOfQueerin2023QueerAI)* won ***Best Paper at FAccT 2023***!
05/2023,ğŸ“°ğŸ,Really excited to unveil the camera-ready versions of our ACL papers: *[Detoxifying Text with MaRCo: Controllable Revision with Experts and Anti-Experts](./pdfs/hallinan2023marco.pdf)*, *[NLPositionality: Characterizing Design Biases of Datasets and Models](./pdfs/santy2023nlpositionality.pdf)*, *[From Dogwhistles to Bullhorns: Unveiling Coded Rhetoric with Language Models](./pdfs/mendelsohn2023dogwhistles.pdf)*, *[COBRA Frames: Contextual Reasoning about Effects and Harms of Offensive Statements](./pdfs/zhou2023cobraframes.pdf)*, and our demo *[Riveter: Measuring Power and Social Dynamics Between Entities](./pdfs/antoniak2023riveter.pdf)*.
04/2023,ğŸ§ ğŸ¤–,Given recent discussion around ChatGPT/GPT-4 and neural ToM, we updated our <a href="https://arxiv.org/abs/2210.13312">arXiv paper</a> to quantitatively measure ToM abilities in these new closed-source OpenAI models. TLDR; they still don't have ToM. See Appendix D for new results.
03/2023,ğŸ—ğŸ“°,Super excited to have our EMNLP 2022 Neural ToM paper covered by the <a href="https://web.archive.org/web/20230327184321/https://www.nytimes.com/2023/03/27/science/ai-machine-learning-chatbots.html">New York Times</a>, and our EMNLP 2022 Prosocial Dialogues work covered by the <a href="https://web.archive.org/web/20230327201644/https://www.sciencefocus.com/news/chatgpt-ted-lasso-internet-hate-speech/">BBC Science Focus</a>!
01/2023,ğŸ‘¨ğŸ¼â€ğŸ«,Been working really hard at teaching my first class (with my wonderful co-instructor <a href="https://strubell.github.io/">Emma Strubell</a>) on <a href="http://maartensap.com/11-830-Spring2023/">Computational Ethics</a>.
12/2022,âœˆğŸ‡¦ğŸ‡ª,I am attending EMNLP 2022, where I will be presenting our Neural ToM paper and Hyunwoo Kim will be presenting our Prosocial Dialog paper.
11/2022,âœ‰ï¸ğŸ§‘â€ğŸ“,<em>PhD recruiting info</em>: I will likely be taking at most one student this year, likely to work in the areas of <em>social biases, content moderation, and fairness/ethics/justice in AI/NLP</em>. If you want to work with me, I encourage y'all to apply to CMU directly instead of emailing me. Please see more information <a href="websiteRoot/contact.html#applying-to-work-with-me">here</a>.
11/2022,ğŸ‘¨ğŸ¼â€ğŸ«,Excited to give a talk at the Minnesota NLP seminar, at Amazon, and at the MIT Media lab: <em>Toward Prosocial NLP: Reasoning About And Responding to Toxicity in Language</em>.
10/2022,ğŸ’­ğŸ‘¥,Two papers accepted to ğŸ‡¦ğŸ‡ª EMNLP 2022 ğŸ‡¦ğŸ‡ª! "<em><a href="websiteRoot/publications.html#sap2022neuralToM">Neural Theory-of-Mind? On the Limits of Social Intelligence in Large LMs</a></em>" ğŸ¤–ğŸ’­ and "<em><a href="websiteRoot/publications.html#kim2022prosocialDialog">ProsocialDialog: A Prosocial Backbone for Conversational Agents</a></em>" ğŸ—£ğŸ’¬.
10/2022,âœˆğŸ—½,I'm attending Text as Data (<a href="http://tada2022.org">TADA2022</a>) in New York City, where my AI2 intern <a href="https://juliamendelsohn.github.io/">Julia Mendelsohn</a> will be presenting our work on NLP and dogwhistles.
10/2022,ğŸ“„ğŸ§ ,Super excited to have my first PNAS paper accepted: "<em><a href="websiteRoot/publications.html#sap2022quantifying">Quantifying the narrative flow of imagined versus autobiographical stories</a></em>" out soon!
09/2022,ğŸ“„âš–,Excited to have my first NeurIPS paper accepted, and as an oral presentation too, called "<em><a href="https://arxiv.org/abs/2210.01478">Rule-Based but Flexible? Evaluating and Improving Language Models as Accounts of Human Moral Judgment</a></em>."
08/2022,âœˆğŸ™,I moved to Pittsburgh to officially start at <a href="https://www.lti.cs.cmu.edu/" target="_blank">CMU's LTI</a> department as an assistant professorğŸ‘¨ğŸ¼â€ğŸ«. â€
07/2022,ğŸ‘¨ğŸ¼â€ğŸ«,I'll be attending NAACL and giving a talk about <em><a href="websiteRoot/publications.html#sap2022annotatorsWithAttitudes">Annotators with Attitudes</a></em> during session 5A: "<em>Ethics, Bias, Fairness 1</em>" between 14:15 â€“ 15:45 PST Tuesday July 12.
04/2022,,Giving a keynote talk at the <a href="https://caisa.informatik.uni-marburg.de/user_nlp.html">UserNLP: User-centered Natural Language Processing Workshop</a> collocated with <a href="https://www2022.thewebconf.org/">the WebConf 2022</a> on my research! Video coming soon.
04/2022,ğŸ‘¨ğŸ¼â€ğŸ«,I gave a talk at UPenn's Computational Linguistics Lunch (CLunch) on <em>Detecting and Rewriting Social Biases in Language</em>.
04/2022,ğŸ“„,Excited that we have two papers accepted to NAACL 2022 in â˜” Seattle ğŸ”: our preprint on annotator variation in toxicity labelling: <em><a href="websiteRoot/publications.html#sap2022annotatorsWithAttitudes">Annotators with Attitudes: How Annotator Beliefs And Identities Bias Toxic Language Detection</a></em>, and our new work on steering agents to do the "right thing" in text games with reinforcement learning: <em><a href="websiteRoot/publications.html#ammanabrolu2022galad">Aligning to Social Norms and Values in Interactive Narratives</a></em>
02/2022,ğŸ“„,Got two papers accepted to ACL 2022 in ğŸ€ Dublin ğŸ€: our paper on generating hate speech datasets with GPT-3: <em><a href="websiteRoot/publications.html#hartvigsen2022toxigen">TOXIGEN: Controlling Language Models to Generate Implied and Adversarial Toxicity</a></em>, and our paper on distilling reactions to headlines to combat misinformation: <em><a href="websiteRoot/publications.html#gabriel2022misinfoReactionFrames">Misinfo Reaction Frames: Reasoning about Readers' Reactions to News Headlines</a></em>
02/2022,ğŸ‘¨ğŸ¼â€ğŸ«,I gave an invited talk at UIUC's Responsible Data Science seminar on my research.
02/2022,ğŸ‘¨ğŸ¼â€ğŸ«,I gave guest lectures on <em>Detecting and Rewriting Social Biases in Language</em> at <a href="https://web.stanford.edu/class/cs224n/">Stanford's Deep Learning for NLP course (CS224N)</a> and at LTI's Computational Ethics course (CS 11-830), and a guest lecture on <em>Positive AI with Social Commonsense Models</em> in UBC's commonsense reasoning course.
12/2021,ğŸ§‘â€ğŸ“,I will likely be taking students this coming PhD application cycle. If you're interested in working with me on <em>social commonsense, social biases in language, or ethics in AI</em>, please apply to <a href="https://www.lti.cs.cmu.edu/apply-lti" target="_blank">CMU's LTI</a>.
07/2021,ğŸ‘¨ğŸ¼â€ğŸ“,I successfully defended my PhD thesis titled <em>Positive AI with Social Commonsense Models</em> (<a target="_blank" href="pdfs/sap2021positiveAIwithSocialCommonsenseModels.pdf">read the thesis here</a>, or <a href="https://www.youtube.com/watch?v=VKd4Y7Ykh6o" target="_blank">watch the recording here<a/>). Thanks to my advisors, committee, and everyone who attended!
05/2021,ğŸ¥³,I will be joining <a href="https://www.lti.cs.cmu.edu/" target="_blank">CMU's LTI</a> department as an assistant professorğŸ‘¨ğŸ¼â€ğŸ«in Fall 2022. If you wish to work with me, <a href="contact.html">see the "contact" page</a>. Before starting there, I will be a postdoc at <a href="https://allenai.org" target="_blank">AI2</a> on project <a target="_blank" href="https://allenai.org/commonsense/">Mosaic</a> ğŸ‘¨ğŸ¼â€ğŸ”¬ starting Fall 2021.
01/2021,ğŸ“°,...started this list ğŸ˜ which I probably should have done sooner ğŸ˜…